"""
 * @author: zkyuan
 * @date: 2025/4/8 10:53
 * @description: ä½¿ç”¨å¤§æ¨¡å‹åšocrè¯†åˆ«
"""

import base64  # base64 ç”¨äºå¤„ç† Base64 ç¼–ç 

import requests  # requests ç”¨äºå‘é€ HTTP è¯·æ±‚
import streamlit as st

from config.constant import *
from config.entry import *


# è¿™æ®µä»£ç å®šä¹‰äº†ä¸€ä¸ªåä¸º vision_page çš„å‡½æ•°ï¼Œå¹¶è®¾ç½®äº†é¡µé¢æ ‡é¢˜å’Œæè¿°ï¼Œè§£é‡Šäº† GPT-4o çš„åŠŸèƒ½åŠå…¶å½“å‰çš„é™åˆ¶ã€‚
def image_to_markdown_page():
    st.title("ğŸ¤– å›¾ç‰‡è¯†åˆ«åŠ©æ‰‹")
    st.caption(
        "è¿™ä¸ªé¡µé¢çš„åŠŸèƒ½æ²¡ä½ æƒ³è±¡çš„é‚£ä¹ˆå¥½ã€‚\n"
    )
    base_url = MY_QWEN_VL_URL
    # åˆ›å»ºä¸€ä¸ªæ–‡ä»¶ä¸Šä¼ å™¨ï¼Œå…è®¸ç”¨æˆ·ä¸Šä¼ å›¾ç‰‡æ–‡ä»¶ï¼Œå¹¶è®¾ç½®æœ€å¤§æ–‡ä»¶å¤§å°ä¸º 5MBã€‚
    upload_images = st.file_uploader(
        label="æç¤ºï¼šæŠŠæ–‡ä»¶æ‹–åˆ°è¿™é‡Œï¼Œæˆ–è€…ç‚¹å‡»ä¸Šä¼ æŒ‰é’®ï¼Œä¸€æ¬¡åªæ”¯æŒä¸€å¼ å›¾ç‰‡ï¼›ä¸”ä¸è¦ä¸Šä¼ è¶…è¿‡5Mçš„å›¾ç‰‡ã€‚",
        type=IMAGE_TYPE,
        label_visibility="visible",
        accept_multiple_files=False,
        help=f"åªæ”¯æŒ{IMAGE_TYPE}æ ¼å¼",
    )

    # åˆ›å»ºä¸€ä¸ªæ•°å­—è¾“å…¥æ¡†ï¼Œè®©ç”¨æˆ·è¾“å…¥æœ€å¤§ tokens æ•°é‡ï¼Œé»˜è®¤å€¼ä¸º 300ã€‚
    max_tokens = st.number_input("Max tokens(å¦‚æœå›¾ç‰‡å†…å®¹è¿‡å¤šï¼Œå¯ä»¥é€‚å½“è°ƒå¤§ï¼›å¦‚æœå›¾ç‰‡å†…å®¹å°‘ï¼Œå¯ä»¥é€‚å½“è°ƒå°)", min_value=1,
                                 value=500, step=1)

    # æ£€æŸ¥ä¸Šä¼ çš„å›¾ç‰‡æ–‡ä»¶æ˜¯å¦è¶…è¿‡æœ€å¤§å¤§å°ï¼Œå¦‚æœæ²¡æœ‰è¶…è¿‡ï¼Œåˆ™è¯»å–æ–‡ä»¶å†…å®¹å¹¶æ˜¾ç¤ºå›¾ç‰‡ã€‚
    bytes_data = None
    if upload_images is not None:
        if upload_images.size > MAX_FILE_SIZE:
            st.error("The uploaded file is too large. Please upload an image smaller than 5MB.")
        else:
            # image = Image.open(upload_images)
            bytes_data = upload_images.getvalue()
            st.image(bytes_data, caption=upload_images.name, width=200)

    # å¤„ç†ç”¨æˆ·è¾“å…¥çš„æç¤ºä¿¡æ¯ prompt å’Œä¸Šä¼ çš„å›¾ç‰‡
    if prompt := st.chat_input():
        # å¦‚æœç”¨æˆ·è¾“å…¥äº†æç¤ºä¿¡æ¯ï¼Œåˆ™æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯ã€‚
        st.chat_message("user").write(prompt)
        with st.chat_message('assistant'):
            with st.spinner('Thinking...'):
                try:
                    headers = {"Content-Type": "application/json", "Authorization": f"Bearer {MY_QWEN_VL_API_KEY}"}
                    # å¦‚æœä¸Šä¼ äº†å›¾ç‰‡ï¼Œåˆ™å°†å›¾ç‰‡è½¬æ¢ä¸º Base64 ç¼–ç ï¼Œå¹¶æ„å»ºåŒ…å«æ–‡æœ¬å’Œå›¾ç‰‡çš„è¯·æ±‚è´Ÿè½½ã€‚
                    if bytes_data is not None:
                        base64_image = base64.b64encode(bytes_data).decode("utf-8")
                        payload = {
                            # "model": "gpt-4o",
                            "model": MY_QWEN_VL_MODEL_NAME,
                            "messages": [
                                {
                                    "role": "system",
                                    "content": [
                                        {
                                            "type": "text",
                                            "text": my_prompt_vl_Customize(prompt),
                                        },
                                    ],
                                },
                                {
                                    "role": "user",
                                    "content": [
                                        {
                                            "type": "text",
                                            "text": MY_PROMPT_VL_USER,
                                        },
                                        {
                                            "type": "image_url",
                                            "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"},
                                        },
                                    ],
                                },
                            ],
                            "max_tokens": max_tokens,
                        }
                    else:
                        # å¦‚æœæ²¡æœ‰ä¸Šä¼ å›¾ç‰‡ï¼Œåˆ™æ„å»ºä»…åŒ…å«æ–‡æœ¬çš„è¯·æ±‚è´Ÿè½½ã€‚
                        payload = {
                            # "model": "gpt-4o",
                            "model": MY_QWEN_VL_MODEL_NAME,
                            "messages": [
                                {
                                    "role": "user",
                                    "content": prompt,
                                },
                            ],
                            "max_tokens": max_tokens,
                        }
                    # å‘é€è¯·æ±‚åˆ° OpenAI API
                    if base_url.endswith('/'):
                        base_url = base_url[:-1]
                    response = requests.post(
                        base_url + "/chat/completions", headers=headers, json=payload
                    )

                    # æ£€æŸ¥çŠ¶æ€ç æ˜¯å¦æ­£å¸¸ï¼Œä¸æ­£å¸¸ä¼šè§¦å‘å¼‚å¸¸
                    response.raise_for_status()
                    print(response.json())
                    result = response.json()["choices"][0]["message"]["content"]
                    st.markdown(result)
                except Exception as e:
                    st.error(e)
                    st.stop()


if __name__ == "__main__":
    image_to_markdown_page()
